name: "CharLM"
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "cont"
  top: "label"
  hdf5_data_param {
    source: "/home/ec2-user/Knet8-Benchmarks/data/files.txt"
    batch_size: 99 # it's not actually 100
  }
  # dummy_data_param {
  #   shape {
  #     dim: 100
  #     dim: 128
  #     # dim: 1
  #   }
  #   data_filler: { type: "constant" value: 84 }
  #   shape {
  #     dim: 100
  #     dim: 128
  #     # dim: 1
  #   }
  #   data_filler: { type: "constant" value: 0 }
  #   shape {
  #     dim: 100
  #     dim: 128
  #     # dim: 1
  #   }
  #   data_filler: { type: "constant" value: 7 }
  # }
}

# embed layer
layer {
  name: "embed"
  type: "Embed"
  bottom: "data"
  top: "embed"
  embed_param {
    bias_term: false
    input_dim: 84
    num_output: 256 # embedsize
    weight_filler {
      type: "gaussian"
      std: 0.3
    }
  }
}

# lstm layer
layer {
  name: "lstm"
  type: "LSTM"
  bottom: "embed"
  bottom: "cont"
  top: "lstm"
  recurrent_param {
    num_output: 256 # cell capacity
    weight_filler {
      type: "gaussian"
      std: 0.3
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

# predict layer
layer {
  name: "predict"
  type: "InnerProduct"
  bottom: "lstm"
  top: "predict"
  inner_product_param {
    num_output: 84
    weight_filler {
      type: "uniform"
      min: -0.08
      max: 0.08
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}

# cross entropy loss layer
layer {
  name: "cross_entropy_loss"
  type: "SoftmaxWithLoss"
  bottom: "predict"
  bottom: "label"
  top: "cross_entropy_loss"
  softmax_param { axis: 2 }
}
